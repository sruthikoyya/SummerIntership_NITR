{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sruthikoyya/SummerIntership_NITR/blob/main/UNet_NITR_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcc64HUWNBr_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRSJdc0Ykzxc"
      },
      "outputs": [],
      "source": [
        "def normalize(datapoint):\n",
        "    image = tf.image.resize(datapoint['image'], (572, 572))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "    mask = tf.image.resize(datapoint['segmentation_mask'], (388, 388))\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    mask = tf.where(mask > 0, 1.0, 0.0)\n",
        "    mask = tf.expand_dims(mask, axis=-1)\n",
        "\n",
        "    return image, mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMZlZJyKYqt4"
      },
      "outputs": [],
      "source": [
        "train_ds = tfds.load('oxford_iiit_pet:4.*.*', split='train[:80%]', as_supervised=False)\n",
        "val_ds = tfds.load('oxford_iiit_pet:4.*.*', split='train[80%:]', as_supervised=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybNiVfVXZ7Ch"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(normalize).batch(8).prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(normalize).batch(8).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMAtIzwQakve"
      },
      "outputs": [],
      "source": [
        "#Convolution block\n",
        "def conv_block(x, filters):\n",
        "    x = tf.keras.layers.Conv2D(filters, 3, activation='relu', padding='valid')(x)\n",
        "    x = tf.keras.layers.Conv2D(filters, 3, activation='relu', padding='valid')(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2QLXYP2c5lT"
      },
      "outputs": [],
      "source": [
        "#Crop and concat the contracting path to expansive path\n",
        "def crop_and_concat(down, up):\n",
        "    dh, dw = down.shape[1] - up.shape[1], down.shape[2] - up.shape[2]\n",
        "    down = tf.keras.layers.Cropping2D(((dh//2, dh - dh//2), (dw//2, dw - dw//2)))(down)\n",
        "    return tf.keras.layers.Concatenate()([down, up])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BUmNkGvdErI"
      },
      "outputs": [],
      "source": [
        "def unet_model():\n",
        "    inputs = tf.keras.Input(shape=(572, 572, 3))\n",
        "    c1 = conv_block(inputs, 64)\n",
        "    p1 = tf.keras.layers.MaxPool2D()(c1)\n",
        "\n",
        "    c2 = conv_block(p1, 128)\n",
        "    p2 = tf.keras.layers.MaxPool2D()(c2)\n",
        "\n",
        "    c3 = conv_block(p2, 256)\n",
        "    p3 = tf.keras.layers.MaxPool2D()(c3)\n",
        "\n",
        "    c4 = conv_block(p3, 512)\n",
        "    p4 = tf.keras.layers.MaxPool2D()(c4)\n",
        "\n",
        "    c5 = conv_block(p4, 1024)\n",
        "\n",
        "    u6 = tf.keras.layers.Conv2DTranspose(512, 2, strides=2, padding='valid')(c5)\n",
        "    u6 = crop_and_concat(c4, u6)\n",
        "    c6 = conv_block(u6, 512)\n",
        "\n",
        "    u7 = tf.keras.layers.Conv2DTranspose(256, 2, strides=2, padding='valid')(c6)\n",
        "    u7 = crop_and_concat(c3, u7)\n",
        "    c7 = conv_block(u7, 256)\n",
        "\n",
        "    u8 = tf.keras.layers.Conv2DTranspose(128, 2, strides=2, padding='valid')(c7)\n",
        "    u8 = crop_and_concat(c2, u8)\n",
        "    c8 = conv_block(u8, 128)\n",
        "\n",
        "    u9 = tf.keras.layers.Conv2DTranspose(64, 2, strides=2, padding='valid')(c8)\n",
        "    u9 = crop_and_concat(c1, u9)\n",
        "    c9 = conv_block(u9, 64)\n",
        "\n",
        "    outputs = tf.keras.layers.Conv2D(1, 1, activation='sigmoid')(c9)\n",
        "    return tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaM7CtEIeBF-"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "\n",
        "def flatten(y):\n",
        "    return K.flatten(tf.squeeze(y, axis=-1)) if len(y.shape) == 4 else K.flatten(y)\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    y_true_f = flatten(y_true)\n",
        "    y_pred_f = flatten(K.round(y_pred))\n",
        "\n",
        "    tp = K.sum(y_true_f * y_pred_f)\n",
        "    fp = K.sum((1 - y_true_f) * y_pred_f)\n",
        "    return tp / (tp + fp + K.epsilon())\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    y_true_f = flatten(y_true)\n",
        "    y_pred_f = flatten(K.round(y_pred))\n",
        "\n",
        "    tp = K.sum(y_true_f * y_pred_f)\n",
        "    fn = K.sum(y_true_f * (1 - y_pred_f))\n",
        "    return tp / (tp + fn + K.epsilon())\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    prec = precision_m(y_true, y_pred)\n",
        "    rec = recall_m(y_true, y_pred)\n",
        "    return 2 * (prec * rec) / (prec + rec + K.epsilon())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAGPSoqmB2sJ"
      },
      "outputs": [],
      "source": [
        "def iou(y_true, y_pred, smooth=1e-6):\n",
        "    # Use tf.cond instead of Python if\n",
        "    y_true = tf.cond(\n",
        "        tf.equal(tf.rank(y_true), 5),\n",
        "        lambda: tf.squeeze(y_true, axis=-1),\n",
        "        lambda: y_true\n",
        "    )\n",
        "    y_pred = tf.cond(\n",
        "        tf.equal(tf.rank(y_pred), 5),\n",
        "        lambda: tf.squeeze(y_pred, axis=-1),\n",
        "        lambda: y_pred\n",
        "    )\n",
        "\n",
        "    y_true_f = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
        "    y_pred_f = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=1)\n",
        "    total = tf.reduce_sum(y_true_f + y_pred_f, axis=1)\n",
        "    union = total - intersection\n",
        "\n",
        "    iou = tf.reduce_mean((intersection + smooth) / (union + smooth))\n",
        "    return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gMPsR8K_8i5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
        "    y_true = tf.cond(\n",
        "        tf.equal(tf.rank(y_true), 5),\n",
        "        lambda: tf.squeeze(y_true, axis=-1),\n",
        "        lambda: y_true\n",
        "    )\n",
        "    y_pred = tf.cond(\n",
        "        tf.equal(tf.rank(y_pred), 5),\n",
        "        lambda: tf.squeeze(y_pred, axis=-1),\n",
        "        lambda: y_pred\n",
        "    )\n",
        "\n",
        "    y_true_f = tf.reshape(y_true, [tf.shape(y_true)[0], -1])\n",
        "    y_pred_f = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])\n",
        "\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=1)\n",
        "    union = tf.reduce_sum(y_true_f, axis=1) + tf.reduce_sum(y_pred_f, axis=1)\n",
        "\n",
        "    dice = tf.reduce_mean((2. * intersection + smooth) / (union + smooth))\n",
        "    return dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iltLbTlXkIeP"
      },
      "outputs": [],
      "source": [
        "model = unet_model()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[\n",
        "                  'accuracy',\n",
        "                  tf.keras.metrics.MeanIoU(num_classes=2),\n",
        "                  dice_coef,\n",
        "                  iou,\n",
        "                  precision_m,\n",
        "                  recall_m,\n",
        "                  f1_score\n",
        "              ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3eXqTjbkOBb",
        "outputId": "a2834a14-bfce-4240-f20c-9898e45a7ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m108/368\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:00:25\u001b[0m 166s/step - accuracy: 0.9972 - dice_coef: 0.9667 - f1_score: 0.9985 - iou: 0.9481 - loss: 0.0690 - mean_io_u: 0.4289 - precision_m: 1.0000 - recall_m: 0.9972"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "history = model.fit(train_ds,\n",
        "                    epochs=10,\n",
        "                    validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcP-V793hOPz"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Evaluate on validation\n",
        "results = model.evaluate(val_ds)\n",
        "for name, val in zip(model.metrics_names, results):\n",
        "    print(f\"{name}: {val:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hy4I-7cmE1I"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}